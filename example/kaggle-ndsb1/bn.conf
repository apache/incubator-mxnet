
data = train
iter = imgrec
  shuffle = 1
  image_list = "../data/train.lst"
  image_rec  = "../data/train.rec"
  image_mean = "models/image_mean.bin"
  rand_mirror=1
  rand_crop=1
  max_aspect_ratio = 0.5
  max_rotate_angle=180
  max_shear_ratio=0.5
  min_crop_size=70
  max_crop_size=70
  min_random_scale = 0.4
  max_random_scale = 1.8
  min_img_size = 80
  max_img_size = 136
iter = threadbuffer
iter = end


netconfig=start
layer[0->1] = conv
  kernel_size = 3
  stride = 1
  nchannel = 32
  pad = 1
  random_type = gaussian
  init_sigma = 0.03
layer[1->2] = relu
layer[2->3] = conv
  kernel_size = 3
  stride = 1
  nchannel = 32
  pad = 1
layer[3->4] = batch_norm
layer[4->5] = relu
layer[5->6] = max_pooling
  kernel_size = 3
  stride = 2
layer[6->7] = conv
  kernel_size = 3
  stride = 1
  pad = 1
  nchannel = 64
layer[7->8] = relu
layer[8->9] = conv
  kernel_size = 3
  stride = 1
  pad = 1
  nchannel = 64
layer[9->10] = relu
layer[10->11] = conv
  kernel_size = 3
  stride = 1
  pad = 1
  nchannel = 64
  random_type = gaussian
  init_sigma = 0.031
layer[11->12] = batch_norm
layer[12->13] = relu
layer[13->14] = max_pooling
  kernel_size = 3
  stride = 2
layer[14->15.1,16.1] = split
layer[15.1->15.2] = conv
  kernel_size = 3
  stride = 1
  pad = 1
  nchannel = 96
layer[15.2->15.3] = relu
layer[15.3->15.4] = conv
  kernel_size = 3
  stride = 1
  pad = 1
  nchannel = 96
layer[15.4->15.5] = relu
layer[15.5->15.6] = conv
  kernel_size = 3
  stride = 1
  pad = 1
  nchannel = 96
layer[15.6->15.7] = relu
layer[15.7->15.8] = conv
  kernel_size = 3
  stride = 1
  pad = 1
  nchannel = 96
layer[15.8->15.9] = batch_norm
layer[15.9->15.10] = relu
layer[16.1->16.2] = conv
  kernel_size = 3
  stride = 1
  pad = 1
  nchannel = 96
  random_type = gaussian
  init_sigma = 0.0347
layer[16.2->16.3] = relu
layer[16.3->16.4] = conv
  kernel_size = 3
  stride = 1
  pad = 1
  nchannel = 96
  random_type = gaussian
  init_sigma = 0.0347
layer[16.4->16.5] = relu
layer[16.5->16.6] = conv
  kernel_size = 3
  stride = 1
  pad = 1
  nchannel = 96
  random_type = gaussian
  init_sigma = 0.0347
layer[16.6->16.7] = batch_norm
layer[16.7->16.8] = relu
layer[15.10,16.8->17] = ch_concat
layer[17->18] = max_pooling
  kernel_size = 3
  stride = 2
layer[18->19] = conv
  kernel_size = 3
  stride = 1
  pad = 1
  nchannel = 256
layer[19->20] = relu
layer[20->21] = conv
  kernel_size = 3
  stride = 1
  pad = 1
  nchannel = 256
layer[21->22] = relu
layer[22->23] = conv
  kernel_size = 3
  stride = 1
  pad = 1
  nchannel = 256
layer[23->24] = relu
layer[24->25] = conv
  kernel_size = 3
  stride = 1
  pad = 1
  nchannel = 256
  random_type = gaussian
  init_sigma = 0.039
layer[25->26] = relu
layer[26->27] = conv
  kernel_size = 3
  stride = 1
  nchannel = 256
  random_type = gaussian
  init_sigma = 0.036
layer[27->28] = batch_norm
layer[28->29] = relu
layer[29->30,31,32] = split
layer[31->33] = max_pooling
  kernel_size = 2
  stride = 2
layer[32->34] = max_pooling
  kernel_size = 4
  stride = 4
layer[30->35] = flatten
layer[33->36] = flatten
layer[34->37] = flatten
layer[35,36,37->38] = concat
layer[+1] = fullc
  nhidden = 1024
layer[+1] = relu
layer[+0] = dropout
  threshold = 0.6
layer[+1] = fullc
  nhidden = 1024
layer[+1] = relu
layer[+0] = dropout
  threshold = 0.6
layer[+1] = fullc
 nhidden = 121
layer[+0] = softmax
netconfig=end

seed = 20150309
seed_data = 90305102
#device
dev = gpu:0
continue = 0
# evaluation metric
metric = error
metric = logloss
print_step = 1
max_round = 400
num_round = 400
updater = sgd
# input shape not including batch
input_shape = 3,70,70

batch_size = 96
# global parameters in any sectiion outside netconfig, and iter
momentum = 0.90
wmat:lr  = 0.01
wmat:wd  = 0.0005

bias:wd  = 0.000
bias:lr  = 0.02

minimum_lr = 0.00004
# all the learning rate schedule starts with lr
lr:schedule = factor
lr:factor = 0.1
lr:step = 110600

save_model=1
model_dir=models
# random config
random_type = xavier

# new line
