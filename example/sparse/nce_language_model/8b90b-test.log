PYTHONPATH=~/tf/python/ python train.py --checkpoint-dir=./checkpoint0/ --data=/home/ubuntu/gbw-validation/heldout-mo
nolingual.tokenized.shuffled/* --emsize=512 --eps=0 --gpus=0,1,2,3 --nhid=2048 --num_proj=512 --per-ctx-clip --rescale-embed --clip=10 --lr=0.2 --expected-count --where-minus --drop
out=0.1 --log-interval=1 --epoch=1 &> 8b90b-test.log


2018-02-14 02:39:57,582 Namespace(batch_size=128, bench=False, bptt=20, checkpoint_dir='./checkpoint0/', checkpoint_interval=1, clip=10.0, data='/home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/*', dense=False, dropout=0.1, emsize=512, epochs=1, eps=0.0, expected_count=True, gpus='0,1,2,3', init=1, k=8192, kvstore='device', load_epoch=-1, log_interval=1, lr=0.2, nhid=2048, nlayers=1, num_proj=512, per_ctx_clip=True, profile=False, py_sampler=False, rescale_embed=True, seed=1, unique=False, vocab='./data/ptb_vocab.txt', wd=0.0, where_minus=True)
train.py:109: UserWarning: Optimizer created manually outside Module but rescale_grad is not normalized to 1.0/batch_size/num_workers (0.25 vs. 0.001953125). Is this intended?
  module.init_optimizer(optimizer=optimizer, kvstore=kvstore)
2018-02-14 02:40:08,144 Training started ... 
/home/ubuntu/tf/python/mxnet/ndarray/ndarray.py:1874: RuntimeWarning: You are attempting to copy an array to itself
  warnings.warn('You are attempting to copy an array to itself', RuntimeWarning)
2018-02-14 02:40:11,892 Iter[0] Batch [1]	Speed: 44757.19 samples/sec
2018-02-14 02:40:11,892 Iter[0] Batch [1] 	loss 22.0661407, ppl 3830038709.7426815
2018-02-14 02:40:12,121 Iter[0] Batch [2]	Speed: 44835.97 samples/sec
2018-02-14 02:40:12,121 Iter[0] Batch [2] 	loss 9.1035072, ppl 8986.7561411
2018-02-14 02:40:12,349 Iter[0] Batch [3]	Speed: 44943.27 samples/sec
2018-02-14 02:40:12,349 Iter[0] Batch [3] 	loss 104.8892456, ppl -1.0000000
2018-02-14 02:40:12,527 Iter[0] Batch [4]	Speed: 57518.39 samples/sec
2018-02-14 02:40:12,527 Iter[0] Batch [4] 	loss 37.7866241, ppl 25734892363392324.0000000
2018-02-14 02:40:12,769 Iter[0] Batch [5]	Speed: 42354.80 samples/sec
2018-02-14 02:40:12,769 Iter[0] Batch [5] 	loss 8.6202629, ppl 5542.8434652
2018-02-14 02:40:12,958 Iter[0] Batch [6]	Speed: 54401.24 samples/sec
2018-02-14 02:40:12,958 Iter[0] Batch [6] 	loss 14.7830322, ppl 2631414.8533703
2018-02-14 02:40:13,147 Iter[0] Batch [7]	Speed: 53993.91 samples/sec
2018-02-14 02:40:13,148 Iter[0] Batch [7] 	loss 23.0689789, ppl 10440714772.2890129
2018-02-14 02:40:13,324 Iter[0] Batch [8]	Speed: 58056.50 samples/sec
2018-02-14 02:40:13,324 Iter[0] Batch [8] 	loss 12.6087585, ppl 299167.3949126
2018-02-14 02:40:13,482 Iter[0] Batch [9]	Speed: 64852.01 samples/sec
2018-02-14 02:40:13,483 Iter[0] Batch [9] 	loss 9.7684738, ppl 17474.0781974
2018-02-14 02:40:13,656 Iter[0] Batch [10]	Speed: 59063.41 samples/sec
2018-02-14 02:40:13,656 Iter[0] Batch [10] 	loss 11.6309807, ppl 112530.6246140
2018-02-14 02:40:13,815 Iter[0] Batch [11]	Speed: 64505.95 samples/sec
2018-02-14 02:40:13,815 Iter[0] Batch [11] 	loss 9.5567184, ppl 14139.3708600
2018-02-14 02:40:13,966 Iter[0] Batch [12]	Speed: 68012.80 samples/sec
2018-02-14 02:40:13,966 Iter[0] Batch [12] 	loss 8.2122757, ppl 3685.9209641
2018-02-14 02:40:14,131 Iter[0] Batch [13]	Speed: 62197.86 samples/sec
2018-02-14 02:40:14,131 Iter[0] Batch [13] 	loss 15.3633469, ppl 4701287.0179118
2018-02-14 02:40:14,303 Iter[0] Batch [14]	Speed: 59518.90 samples/sec
2018-02-14 02:40:14,303 Iter[0] Batch [14] 	loss 12.9232727, ppl 409737.7931033
2018-02-14 02:40:14,470 Iter[0] Batch [15]	Speed: 61212.13 samples/sec
2018-02-14 02:40:14,471 Iter[0] Batch [15] 	loss 10.3663162, ppl 31771.2230377
2018-02-14 02:40:14,724 Iter[0] Batch [16]	Speed: 40318.30 samples/sec
2018-02-14 02:40:14,725 Iter[0] Batch [16] 	loss 1.5684498, ppl 4.7992026
2018-02-14 02:40:14,975 Iter[0] Batch [17]	Speed: 40960.98 samples/sec
2018-02-14 02:40:14,975 Iter[0] Batch [17] 	loss 1.2277760, ppl 3.4136290
2018-02-14 02:40:15,228 Iter[0] Batch [18]	Speed: 40499.61 samples/sec
2018-02-14 02:40:15,228 Iter[0] Batch [18] 	loss 0.1104013, ppl 1.1167261
2018-02-14 02:40:15,500 Iter[0] Batch [19]	Speed: 37668.51 samples/sec
2018-02-14 02:40:15,500 Iter[0] Batch [19] 	loss 0.0633472, ppl 1.0653967
2018-02-14 02:40:15,768 Iter[0] Batch [20]	Speed: 38299.98 samples/sec
2018-02-14 02:40:15,768 Iter[0] Batch [20] 	loss 0.0585202, ppl 1.0602664
2018-02-14 02:40:16,029 Iter[0] Batch [21]	Speed: 39260.81 samples/sec
2018-02-14 02:40:16,029 Iter[0] Batch [21] 	loss 0.0427677, ppl 1.0436955
2018-02-14 02:40:16,288 Iter[0] Batch [22]	Speed: 39581.78 samples/sec
2018-02-14 02:40:16,288 Iter[0] Batch [22] 	loss 0.0208573, ppl 1.0210764
2018-02-14 02:40:16,654 Saved checkpoint to "./checkpoint0/-0000.params"
2018-02-14 02:40:17,688 Saved optimizer state to "./checkpoint0/-0000.states"
2018-02-14 02:40:18,095 eval batch 1 : 9.6267519
2018-02-14 02:40:18,229 eval batch 2 : 8.9217315
2018-02-14 02:40:18,359 eval batch 3 : 8.7063986
2018-02-14 02:40:18,489 eval batch 4 : 8.6074698
2018-02-14 02:40:18,621 eval batch 5 : 8.5241377
2018-02-14 02:40:18,754 eval batch 6 : 8.5014817
2018-02-14 02:40:18,885 eval batch 7 : 8.4726937
2018-02-14 02:40:19,016 eval batch 8 : 8.4204687
2018-02-14 02:40:19,149 eval batch 9 : 8.3700427
2018-02-14 02:40:19,289 eval batch 10 : 8.3379919
2018-02-14 02:40:19,420 eval batch 11 : 8.3116364
2018-02-14 02:40:19,551 eval batch 12 : 8.2862552
2018-02-14 02:40:19,681 eval batch 13 : 8.2715617
2018-02-14 02:40:19,826 eval batch 14 : 8.2764995
2018-02-14 02:40:19,975 eval batch 15 : 8.2776160
2018-02-14 02:40:20,108 eval batch 16 : 8.2826333
2018-02-14 02:40:20,243 eval batch 17 : 8.2686008
2018-02-14 02:40:20,376 eval batch 18 : 8.2632663
2018-02-14 02:40:20,533 eval batch 19 : 8.2443858
2018-02-14 02:40:20,661 eval batch 20 : 8.2307647
2018-02-14 02:40:20,791 eval batch 21 : 8.2232219
2018-02-14 02:40:21,017 eval batch 22 : 8.2179152
2018-02-14 02:40:21,230 eval batch 23 : 8.2168291
2018-02-14 02:40:21,431 eval batch 24 : 8.2194937
2018-02-14 02:40:21,630 eval batch 25 : 8.2182040
2018-02-14 02:40:21,750 eval batch 26 : 8.2120717
2018-02-14 02:40:21,872 eval batch 27 : 8.2125997
2018-02-14 02:40:22,003 eval batch 28 : 8.2077626
2018-02-14 02:40:22,135 eval batch 29 : 8.2019871
2018-02-14 02:40:22,272 eval batch 30 : 8.1959776
2018-02-14 02:40:22,419 eval batch 31 : 8.1953185
2018-02-14 02:40:22,575 eval batch 32 : 8.1983159
2018-02-14 02:40:22,706 eval batch 33 : 8.1953971
2018-02-14 02:40:22,853 eval batch 34 : 8.1831313
2018-02-14 02:40:22,989 eval batch 35 : 8.1851436
2018-02-14 02:40:23,124 eval batch 36 : 8.1856181
2018-02-14 02:40:23,285 eval batch 37 : 8.1851905
2018-02-14 02:40:23,454 eval batch 38 : 8.1919381
2018-02-14 02:40:23,599 eval batch 39 : 8.1886279
2018-02-14 02:40:23,746 eval batch 40 : 8.1845926
2018-02-14 02:40:23,862 eval batch 41 : 8.1836124
2018-02-14 02:40:23,997 eval batch 42 : 8.1817154
2018-02-14 02:40:24,122 eval batch 43 : 8.1812468
2018-02-14 02:40:24,244 eval batch 44 : 8.1856148
2018-02-14 02:40:24,380 eval batch 45 : 8.1852994
2018-02-14 02:40:24,524 eval batch 46 : 8.1868848
2018-02-14 02:40:24,662 eval batch 47 : 8.1856816
2018-02-14 02:40:24,773 eval batch 48 : 8.1864622
2018-02-14 02:40:24,906 eval batch 49 : 8.1875067
2018-02-14 02:40:25,023 eval batch 50 : 8.1845130
2018-02-14 02:40:25,145 eval batch 51 : 8.1793330
2018-02-14 02:40:25,252 eval batch 52 : 8.1824239
2018-02-14 02:40:25,362 eval batch 53 : 8.1797589
2018-02-14 02:40:25,484 eval batch 54 : 8.1797359
2018-02-14 02:40:25,630 eval batch 55 : 8.1775790
2018-02-14 02:40:25,744 eval batch 56 : 8.1766976
2018-02-14 02:40:25,946 eval batch 57 : 8.1727555
2018-02-14 02:40:26,084 eval batch 58 : 8.1721164
2018-02-14 02:40:26,221 eval batch 59 : 8.1736489
2018-02-14 02:40:26,367 eval batch 60 : 8.1747928
2018-02-14 02:40:26,536 eval batch 61 : 8.1738597
2018-02-14 02:40:26,690 eval batch 62 : 8.1704505
2018-02-14 02:40:26,899 eval batch 63 : 8.1720650
2018-02-14 02:40:27,049 eval batch 64 : 8.1669777
2018-02-14 02:40:27,235 eval batch 65 : 8.1648258
2018-02-14 02:40:27,387 eval batch 66 : 8.1644682
2018-02-14 02:40:27,527 eval batch 67 : 8.1615481
2018-02-14 02:40:27,653 eval batch 68 : 8.1621649
2018-02-14 02:40:27,792 eval batch 69 : 8.1606041
2018-02-14 02:40:27,929 eval batch 70 : 8.1593929
2018-02-14 02:40:28,069 eval batch 71 : 8.1544301
2018-02-14 02:40:28,215 eval batch 72 : 8.1523785
2018-02-14 02:40:28,354 eval batch 73 : 8.1522591
2018-02-14 02:40:28,493 eval batch 74 : 8.1479394
2018-02-14 02:40:28,702 eval batch 75 : 8.1486017
2018-02-14 02:40:28,839 eval batch 76 : 8.1474831
2018-02-14 02:40:29,068 eval batch 77 : 8.1471881
2018-02-14 02:40:29,238 eval batch 78 : 8.1491240
2018-02-14 02:40:29,400 eval batch 79 : 8.1499180
2018-02-14 02:40:29,622 eval batch 80 : 8.1503219
2018-02-14 02:40:29,778 eval batch 81 : 8.1511781
2018-02-14 02:40:29,926 eval batch 82 : 8.1535453
2018-02-14 02:40:30,070 eval batch 83 : 8.1549784
2018-02-14 02:40:30,229 eval batch 84 : 8.1559312
2018-02-14 02:40:30,373 eval batch 85 : 8.1557321
2018-02-14 02:40:30,524 eval batch 86 : 8.1564536
2018-02-14 02:40:30,658 eval batch 87 : 8.1576724
2018-02-14 02:40:30,780 eval batch 88 : 8.1584611
2018-02-14 02:40:30,890 eval batch 89 : 8.1599879
2018-02-14 02:40:31,028 eval batch 90 : 8.1586676
2018-02-14 02:40:31,165 eval batch 91 : 8.1568497
2018-02-14 02:40:31,292 eval batch 92 : 8.1560889
2018-02-14 02:40:31,402 eval batch 93 : 8.1573267
2018-02-14 02:40:31,539 eval batch 94 : 8.1544308
2018-02-14 02:40:31,812 eval batch 95 : 8.1549343
2018-02-14 02:40:31,952 eval batch 96 : 8.1541646
2018-02-14 02:40:32,196 eval batch 97 : 8.1528444
2018-02-14 02:40:32,402 eval batch 98 : 8.1545399
2018-02-14 02:40:32,624 eval batch 99 : 8.1540019
2018-02-14 02:40:32,823 eval batch 100 : 8.1546034
2018-02-14 02:40:32,988 eval batch 101 : 8.1523626
2018-02-14 02:40:33,103 eval batch 102 : 8.1520437
2018-02-14 02:40:33,281 eval batch 103 : 8.1509262
2018-02-14 02:40:33,422 eval batch 104 : 8.1496764
2018-02-14 02:40:33,535 eval batch 105 : 8.1489171
2018-02-14 02:40:33,707 eval batch 106 : 8.1486896
2018-02-14 02:40:33,904 eval batch 107 : 8.1465357
2018-02-14 02:40:34,073 eval batch 108 : 8.1449957
2018-02-14 02:40:34,230 eval batch 109 : 8.1465978
2018-02-14 02:40:34,358 eval batch 110 : 8.1435943
2018-02-14 02:40:34,489 eval batch 111 : 8.1460879
2018-02-14 02:40:34,647 eval batch 112 : 8.1465333
2018-02-14 02:40:34,788 eval batch 113 : 8.1478066
2018-02-14 02:40:34,896 eval batch 114 : 8.1486153
2018-02-14 02:40:34,998 eval batch 115 : 8.1477583
2018-02-14 02:40:35,100 eval batch 116 : 8.1477630
2018-02-14 02:40:35,250 eval batch 117 : 8.1470545
2018-02-14 02:40:35,374 eval batch 118 : 8.1474720
2018-02-14 02:40:35,529 eval batch 119 : 8.1437679
2018-02-14 02:40:35,747 eval batch 120 : 8.1450759
2018-02-14 02:40:35,878 eval batch 121 : 8.1445744
2018-02-14 02:40:36,007 eval batch 122 : 8.1459857
2018-02-14 02:40:36,136 eval batch 123 : 8.1458586
2018-02-14 02:40:36,253 eval batch 124 : 8.1459865
2018-02-14 02:40:36,356 eval batch 125 : 8.1473126
2018-02-14 02:40:36,455 eval batch 126 : 8.1471099
2018-02-14 02:40:36,562 eval batch 127 : 8.1491303
2018-02-14 02:40:36,662 eval batch 128 : 8.1508924
2018-02-14 02:40:36,762 eval batch 129 : 8.1508485
2018-02-14 02:40:37,085 eval batch 130 : 8.1524776
2018-02-14 02:40:37,268 eval batch 131 : 8.1504298
2018-02-14 02:40:37,436 eval batch 132 : 8.1508107
2018-02-14 02:40:37,603 eval batch 133 : 8.1508854
2018-02-14 02:40:37,772 eval batch 134 : 8.1515014
2018-02-14 02:40:37,914 eval batch 135 : 8.1510344
2018-02-14 02:40:38,092 eval batch 136 : 8.1515256
2018-02-14 02:40:38,305 eval batch 137 : 8.1497602
2018-02-14 02:40:38,524 eval batch 138 : 8.1490479
2018-02-14 02:40:38,697 eval batch 139 : 8.1490950
2018-02-14 02:40:38,873 eval batch 140 : 8.1498850
2018-02-14 02:40:38,996 eval batch 141 : 8.1510608
2018-02-14 02:40:39,130 eval batch 142 : 8.1524168
2018-02-14 02:40:39,265 eval batch 143 : 8.1534521
2018-02-14 02:40:39,409 eval batch 144 : 8.1522046
2018-02-14 02:40:39,535 eval batch 145 : 8.1534508
2018-02-14 02:40:39,658 eval batch 146 : 8.1537407
2018-02-14 02:40:39,900 eval batch 147 : 8.1532122
2018-02-14 02:40:40,036 eval batch 148 : 8.1541239
2018-02-14 02:40:40,166 eval batch 149 : 8.1547398
2018-02-14 02:40:40,297 eval batch 150 : 8.1550235
2018-02-14 02:40:40,543 eval batch 151 : 8.1561103
2018-02-14 02:40:40,813 eval batch 152 : 8.1555077
2018-02-14 02:40:40,952 eval batch 153 : 8.1562351
2018-02-14 02:40:41,104 eval batch 154 : 8.1587262
2018-02-14 02:40:41,296 eval batch 155 : 8.1592827
2018-02-14 02:40:41,493 eval batch 156 : 8.1592727
2018-02-14 02:40:41,687 eval batch 157 : 8.1596359
2018-02-14 02:40:41,840 eval batch 158 : 8.1608395
2018-02-14 02:40:42,008 eval batch 159 : 8.1613861
2018-02-14 02:40:42,167 eval batch 160 : 8.1632535
2018-02-14 02:40:42,296 eval batch 161 : 8.1636214
2018-02-14 02:40:42,417 eval batch 162 : 8.1626825
2018-02-14 02:40:42,637 eval batch 163 : 8.1639361
2018-02-14 02:40:42,777 eval batch 164 : 8.1648502
2018-02-14 02:40:42,907 eval batch 165 : 8.1652064
2018-02-14 02:40:43,121 eval batch 166 : 8.1650261
2018-02-14 02:40:43,316 eval batch 167 : 8.1665248
2018-02-14 02:40:43,452 eval batch 168 : 8.1668911
2018-02-14 02:40:43,580 eval batch 169 : 8.1688165
2018-02-14 02:40:43,710 eval batch 170 : 8.1692658
2018-02-14 02:40:43,839 eval batch 171 : 8.1692008
2018-02-14 02:40:43,990 eval batch 172 : 8.1693055
2018-02-14 02:40:44,119 eval batch 173 : 8.1708617
2018-02-14 02:40:44,243 eval batch 174 : 8.1712217
2018-02-14 02:40:44,519 eval batch 175 : 8.1717598
2018-02-14 02:40:44,672 eval batch 176 : 8.1721994
2018-02-14 02:40:44,878 eval batch 177 : 8.1730569
2018-02-14 02:40:45,024 eval batch 178 : 8.1726224
2018-02-14 02:40:45,151 eval batch 179 : 8.1744026
2018-02-14 02:40:45,334 eval batch 180 : 8.1742378
2018-02-14 02:40:45,502 eval batch 181 : 8.1751504
2018-02-14 02:40:45,667 eval batch 182 : 8.1730065
2018-02-14 02:40:45,778 eval batch 183 : 8.1721151
2018-02-14 02:40:45,881 eval batch 184 : 8.1738241
2018-02-14 02:40:45,988 eval batch 185 : 8.1737699
2018-02-14 02:40:46,156 eval batch 186 : 8.1725595
2018-02-14 02:40:46,304 eval batch 187 : 8.1745976
2018-02-14 02:40:46,450 eval batch 188 : 8.1744321
2018-02-14 02:40:46,602 eval batch 189 : 8.1753450
2018-02-14 02:40:46,802 eval batch 190 : 8.1757044
2018-02-14 02:40:46,970 eval batch 191 : 8.1769239
2018-02-14 02:40:47,213 eval batch 192 : 8.1762608
2018-02-14 02:40:47,354 eval batch 193 : 8.1760344
2018-02-14 02:40:47,487 eval batch 194 : 8.1741438
2018-02-14 02:40:47,696 eval batch 195 : 8.1741271
2018-02-14 02:40:47,884 eval batch 196 : 8.1733789
2018-02-14 02:40:48,069 eval batch 197 : 8.1726750
2018-02-14 02:40:48,217 eval batch 198 : 8.1719621
2018-02-14 02:40:48,391 eval batch 199 : 8.1719412
2018-02-14 02:40:48,593 eval batch 200 : 8.1708668
2018-02-14 02:40:48,727 eval batch 201 : 8.1711332
2018-02-14 02:40:48,862 eval batch 202 : 8.1712190
2018-02-14 02:40:48,997 eval batch 203 : 8.1724404
2018-02-14 02:40:49,136 eval batch 204 : 8.1716809
2018-02-14 02:40:49,276 eval batch 205 : 8.1709312
2018-02-14 02:40:49,436 eval batch 206 : 8.1697246
2018-02-14 02:40:49,678 eval batch 207 : 8.1681636
2018-02-14 02:40:49,816 eval batch 208 : 8.1686905
2018-02-14 02:40:49,930 eval batch 209 : 8.1692689
2018-02-14 02:40:50,030 eval batch 210 : 8.1687478
2018-02-14 02:40:50,134 eval batch 211 : 8.1693703
2018-02-14 02:40:50,236 eval batch 212 : 8.1713334
2018-02-14 02:40:50,342 eval batch 213 : 8.1711804
2018-02-14 02:40:50,474 eval batch 214 : 8.1705755
2018-02-14 02:40:50,608 eval batch 215 : 8.1708020
2018-02-14 02:40:50,734 eval batch 216 : 8.1702640
2018-02-14 02:40:50,850 eval batch 217 : 8.1698592
2018-02-14 02:40:50,962 eval batch 218 : 8.1694734
2018-02-14 02:40:51,215 eval batch 219 : 8.1693360
2018-02-14 02:40:51,427 eval batch 220 : 8.1701942
2018-02-14 02:40:51,570 eval batch 221 : 8.1701170
2018-02-14 02:40:51,699 eval batch 222 : 8.1705887
2018-02-14 02:40:51,830 eval batch 223 : 8.1706644
2018-02-14 02:40:51,934 eval batch 224 : 8.1703589
2018-02-14 02:40:52,080 eval batch 225 : 8.1709690
2018-02-14 02:40:52,204 eval batch 226 : 8.1710501
2018-02-14 02:40:52,330 eval batch 227 : 8.1710410
2018-02-14 02:40:52,479 eval batch 228 : 8.1708399
2018-02-14 02:40:52,639 eval batch 229 : 8.1706187
2018-02-14 02:40:52,793 eval batch 230 : 8.1708771
2018-02-14 02:40:52,933 eval batch 231 : 8.1697987
2018-02-14 02:40:53,068 eval batch 232 : 8.1695495
2018-02-14 02:40:53,215 eval batch 233 : 8.1701280
2018-02-14 02:40:53,338 eval batch 234 : 8.1711394
2018-02-14 02:40:53,472 eval batch 235 : 8.1718095
2018-02-14 02:40:53,596 eval batch 236 : 8.1721082
2018-02-14 02:40:53,715 eval batch 237 : 8.1728055
2018-02-14 02:40:53,884 eval batch 238 : 8.1719040
2018-02-14 02:40:54,040 eval batch 239 : 8.1715381
2018-02-14 02:40:54,182 eval batch 240 : 8.1707861
2018-02-14 02:40:54,457 eval batch 241 : 8.1718345
2018-02-14 02:40:54,710 eval batch 242 : 8.1721048
2018-02-14 02:40:54,890 eval batch 243 : 8.1722087
2018-02-14 02:40:55,086 eval batch 244 : 8.1718150
2018-02-14 02:40:55,249 eval batch 245 : 8.1716636
2018-02-14 02:40:55,400 eval batch 246 : 8.1719096
2018-02-14 02:40:55,512 eval batch 247 : 8.1712958
2018-02-14 02:40:55,621 eval batch 248 : 8.1724863
2018-02-14 02:40:55,763 eval batch 249 : 8.1666090
2018-02-14 02:40:55,880 eval batch 250 : 8.1457763
2018-02-14 02:40:55,991 eval batch 251 : 8.1162893
2018-02-14 02:40:56,116 eval batch 252 : 8.0850029
2018-02-14 02:40:56,243 eval batch 253 : 8.0537782
2018-02-14 02:40:56,243 Iter[0]		 CE loss 8.0537782, ppl 3145.6575221. Time cost = 38.45 seconds
2018-02-14 02:40:56,244 Training completed. 
['train.py', '--checkpoint-dir=./checkpoint0/', '--data=/home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/*', '--emsize=512', '--eps=0', '--gpus=0,1,2,3', '--nhid=2048', '--num_proj=512', '--per-ctx-clip', '--rescale-embed', '--clip=10', '--lr=0.2', '--expected-count', '--where-minus', '--dropout=0.1', '--log-interval=1', '--epoch=1']
Processing file: /home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/news.en.heldout-00000-of-00050
Finished processing!
['lstm_l0_h2h_bias', 'lstm_l0_i2h_weight', 'lstm_l0_i2h_bias', 'lstm_l0_pj_weight', 'lstm_l0_h2h_weight']
[]
Processing file: /home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/news.en.heldout-00000-of-00050
Finished processing!
reset
reset
Processing file: /home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/news.en.heldout-00000-of-00050
Processing file: /home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/news.en.heldout-00000-of-00050
