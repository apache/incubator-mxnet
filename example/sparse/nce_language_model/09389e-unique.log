2018-01-21 23:40:47,369 Namespace(batch_size=128, bench=False, bptt=20, checkpoint_dir='./checkpoint_1_test/', checkpoint_interval=1, clip=10.0, data='/home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/*', dense=False, dropout=0.1, emsize=512, epochs=5, eps=0.0, gpus='0,1,2,3,4,5,6,7', init=1.0, k=8192, kvstore='device', load_epoch=-1, log_interval=200, lr=0.2, nhid=2048, nlayers=1, num_proj=512, per_ctx_clip=False, profile=False, py_sampler=False, rescale_embed=False, seed=1, unique=True, vocab='./data/1b_word_vocab.txt', wd=0.0, where_minus=False)
train.py:110: UserWarning: Optimizer created manually outside Module but rescale_grad is not normalized to 1.0/batch_size/num_workers (0.125 vs. 0.0009765625). Is this intended?
  module.init_optimizer(optimizer=optimizer, kvstore=kvstore)
2018-01-21 23:41:11,946 Training started ... 
/home/ubuntu/mxnet/python/mxnet/ndarray/ndarray.py:1874: RuntimeWarning: You are attempting to copy an array to itself
  warnings.warn('You are attempting to copy an array to itself', RuntimeWarning)
pass
['train.py', '--nhid', '2048', '--emsize', '512', '--batch_size=128', '--num_proj=512', '--dropout=0.1', '--checkpoint-dir=./checkpoint_1_test/', '--data=/home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/*', '--vocab=./data/1b_word_vocab.txt', '--lr=0.2', '--log-interval=200', '--clip=10', '--checkpoint-interval=1', '--eps=0', '--gpus=0,1,2,3,4,5,6,7', '--init=1', '--unique']
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00007-of-00100
Finished processing!
['lstm_l0_h2h_bias', 'lstm_l0_i2h_weight', 'lstm_l0_i2h_bias', 'lstm_l0_pj_weight', 'lstm_l0_h2h_weight']
[23:41:44] src/kvstore/././comm.h:680: only 32 out of 56 GPU pairs are enabled direct access. It may affect the performance. You can set MXNET_ENABLE_GPU_P2P=0 to turn it off
[23:41:44] src/kvstore/././comm.h:689: .vvvv...
[23:41:44] src/kvstore/././comm.h:689: v.vv.v..
[23:41:44] src/kvstore/././comm.h:689: vv.v..v.
[23:41:44] src/kvstore/././comm.h:689: vvv....v
[23:41:44] src/kvstore/././comm.h:689: v....vvv
[23:41:44] src/kvstore/././comm.h:689: .v..v.vv
[23:41:44] src/kvstore/././comm.h:689: ..v.vv.v
[23:41:44] src/kvstore/././comm.h:689: ...vvvv.
2018-01-21 23:43:13,300 Iter[0] Batch [200]	Speed: 46196.61 samples/sec
2018-01-21 23:43:13,301 Iter[0] Batch [200] 	loss 11.3338770, ppl 83606.5339341
2018-01-21 23:44:43,198 Iter[0] Batch [400]	Speed: 45563.18 samples/sec
2018-01-21 23:44:43,198 Iter[0] Batch [400] 	loss 8.8496416, ppl 6971.8898079
2018-01-21 23:46:12,222 Iter[0] Batch [600]	Speed: 46009.92 samples/sec
2018-01-21 23:46:12,223 Iter[0] Batch [600] 	loss 8.4675293, ppl 4757.7459582
2018-01-21 23:47:42,603 Iter[0] Batch [800]	Speed: 45319.56 samples/sec
2018-01-21 23:47:42,603 Iter[0] Batch [800] 	loss 8.2384883, ppl 3783.8159170
2018-01-21 23:49:10,987 Iter[0] Batch [1000]	Speed: 46343.33 samples/sec
2018-01-21 23:49:10,988 Iter[0] Batch [1000] 	loss 8.0967427, ppl 3283.7543831
2018-01-21 23:50:41,732 Iter[0] Batch [1200]	Speed: 45137.49 samples/sec
2018-01-21 23:50:41,733 Iter[0] Batch [1200] 	loss 7.9720947, ppl 2898.9234606
2018-01-21 23:52:10,939 Iter[0] Batch [1400]	Speed: 45915.99 samples/sec
2018-01-21 23:52:10,940 Iter[0] Batch [1400] 	loss 7.8593145, ppl 2589.7443756
2018-01-21 23:53:41,015 Iter[0] Batch [1600]	Speed: 45473.03 samples/sec
2018-01-21 23:53:41,015 Iter[0] Batch [1600] 	loss 7.7456963, ppl 2311.6025072
2018-01-21 23:55:11,048 Iter[0] Batch [1800]	Speed: 45494.36 samples/sec
2018-01-21 23:55:11,049 Iter[0] Batch [1800] 	loss 7.6474775, ppl 2095.3534704
2018-01-21 23:56:41,267 Iter[0] Batch [2000]	Speed: 45401.04 samples/sec
2018-01-21 23:56:41,267 Iter[0] Batch [2000] 	loss 7.5628276, ppl 1925.2818214
2018-01-21 23:58:10,127 Iter[0] Batch [2200]	Speed: 46095.33 samples/sec
2018-01-21 23:58:10,127 Iter[0] Batch [2200] 	loss 7.4912354, ppl 1792.2648019
2018-01-21 23:59:40,413 Iter[0] Batch [2400]	Speed: 45366.97 samples/sec
2018-01-21 23:59:40,413 Iter[0] Batch [2400] 	loss 7.4274385, ppl 1681.4948637
2018-01-22 00:01:08,777 Iter[0] Batch [2600]	Speed: 46353.80 samples/sec
2018-01-22 00:01:08,778 Iter[0] Batch [2600] 	loss 7.3678408, ppl 1584.2094946
2018-01-22 00:02:38,078 Iter[0] Batch [2800]	Speed: 45867.80 samples/sec
2018-01-22 00:02:38,078 Iter[0] Batch [2800] 	loss 7.3150396, ppl 1502.7312291
2018-01-22 00:04:06,433 Iter[0] Batch [3000]	Speed: 46358.63 samples/sec
2018-01-22 00:04:06,433 Iter[0] Batch [3000] 	loss 7.2639834, ppl 1427.9332505
2018-01-22 00:05:35,888 Iter[0] Batch [3200]	Speed: 45788.41 samples/sec
2018-01-22 00:05:35,888 Iter[0] Batch [3200] 	loss 7.2178213, ppl 1363.5151169
2018-01-22 00:07:05,319 Iter[0] Batch [3400]	Speed: 45800.62 samples/sec
2018-01-22 00:07:05,320 Iter[0] Batch [3400] 	loss 7.1751357, ppl 1306.5374412
2018-01-22 00:08:35,073 Saved checkpoint to "./checkpoint_1_test/-0000.params"
2018-01-22 00:09:26,447 Saved optimizer state to "./checkpoint_1_test/-0000.states"
2018-01-22 00:17:21,591 eval batch 199 : 11.2758387
2018-01-22 00:19:28,825 Iter[0]		 CE loss 11.1912860, ppl 72495.9483972. Time cost = 600.94 seconds
2018-01-22 00:21:01,595 Iter[1] Batch [200]	Speed: 45834.30 samples/sec
2018-01-22 00:21:01,595 Iter[1] Batch [200] 	loss 7.4858750, ppl 1782.6833355
2018-01-22 00:22:32,178 Iter[1] Batch [400]	Speed: 45218.13 samples/sec
2018-01-22 00:22:32,179 Iter[1] Batch [400] 	loss 7.0806167, ppl 1188.7013637
2018-01-22 00:24:01,270 Iter[1] Batch [600]	Speed: 45974.99 samples/sec
2018-01-22 00:24:01,271 Iter[1] Batch [600] 	loss 7.0444565, ppl 1146.4856008
2018-01-22 00:25:33,004 Iter[1] Batch [800]	Speed: 44651.14 samples/sec
2018-01-22 00:25:33,005 Iter[1] Batch [800] 	loss 7.0109077, ppl 1108.6603958
2018-01-22 00:27:00,964 Iter[1] Batch [1000]	Speed: 46567.00 samples/sec
2018-01-22 00:27:00,964 Iter[1] Batch [1000] 	loss 6.9718130, ppl 1066.1539240
2018-01-22 00:28:30,925 Iter[1] Batch [1200]	Speed: 45530.86 samples/sec
2018-01-22 00:28:30,926 Iter[1] Batch [1200] 	loss 6.9429780, ppl 1035.8504171
2018-01-22 00:30:00,099 Iter[1] Batch [1400]	Speed: 45932.97 samples/sec
2018-01-22 00:30:00,099 Iter[1] Batch [1400] 	loss 6.9220654, ppl 1014.4130311
2018-01-22 00:31:30,476 Iter[1] Batch [1600]	Speed: 45321.37 samples/sec
2018-01-22 00:31:30,476 Iter[1] Batch [1600] 	loss 6.8981343, ppl 990.4251321
2018-01-22 00:32:59,050 Iter[1] Batch [1800]	Speed: 46243.77 samples/sec
2018-01-22 00:32:59,051 Iter[1] Batch [1800] 	loss 6.8705435, ppl 963.4720292
2018-01-22 00:34:29,421 Iter[1] Batch [2000]	Speed: 45324.83 samples/sec
2018-01-22 00:34:29,421 Iter[1] Batch [2000] 	loss 6.8487173, ppl 942.6709528
2018-01-22 00:35:57,190 Iter[1] Batch [2200]	Speed: 46668.15 samples/sec
2018-01-22 00:35:57,190 Iter[1] Batch [2200] 	loss 6.8263618, ppl 921.8309141
2018-01-22 00:37:27,816 Iter[1] Batch [2400]	Speed: 45196.99 samples/sec
2018-01-22 00:37:27,816 Iter[1] Batch [2400] 	loss 6.8034492, ppl 900.9495104
2018-01-22 00:38:55,486 Iter[1] Batch [2600]	Speed: 46720.53 samples/sec
2018-01-22 00:38:55,487 Iter[1] Batch [2600] 	loss 6.7877979, ppl 886.9581960
2018-01-22 00:40:25,061 Iter[1] Batch [2800]	Speed: 45727.58 samples/sec
2018-01-22 00:40:25,061 Iter[1] Batch [2800] 	loss 6.7677383, ppl 869.3434584
2018-01-22 00:41:52,837 Iter[1] Batch [3000]	Speed: 46664.31 samples/sec
2018-01-22 00:41:52,837 Iter[1] Batch [3000] 	loss 6.7448115, ppl 849.6389746
2018-01-22 00:43:22,694 Iter[1] Batch [3200]	Speed: 45583.35 samples/sec
2018-01-22 00:43:22,695 Iter[1] Batch [3200] 	loss 6.7287886, ppl 836.1337382
2018-01-22 00:44:51,648 Iter[1] Batch [3400]	Speed: 46046.36 samples/sec
2018-01-22 00:44:51,649 Iter[1] Batch [3400] 	loss 6.7115649, ppl 821.8557898
2018-01-22 00:46:31,889 Saved checkpoint to "./checkpoint_1_test/-0000.params"
2018-01-22 00:47:23,934 Saved optimizer state to "./checkpoint_1_test/-0000.states"
2018-01-22 00:55:17,260 eval batch 199 : 5.9035608
2018-01-22 00:57:24,099 Iter[1]		 CE loss 5.8259351, ppl 338.9779526. Time cost = 598.72 seconds
2018-01-22 00:58:57,374 Iter[2] Batch [200]	Speed: 45544.19 samples/sec
2018-01-22 00:58:57,374 Iter[2] Batch [200] 	loss 6.7158481, ppl 825.3835146
2018-01-22 01:00:28,547 Iter[2] Batch [400]	Speed: 44925.87 samples/sec
2018-01-22 01:00:28,547 Iter[2] Batch [400] 	loss 6.6548120, ppl 776.5119342
2018-01-22 01:01:56,583 Iter[2] Batch [600]	Speed: 46526.41 samples/sec
2018-01-22 01:01:56,583 Iter[2] Batch [600] 	loss 6.6480483, ppl 771.2775840
2018-01-22 01:03:26,339 Iter[2] Batch [800]	Speed: 45634.77 samples/sec
2018-01-22 01:03:26,340 Iter[2] Batch [800] 	loss 6.6315205, ppl 758.6348043
2018-01-22 01:04:55,513 Iter[2] Batch [1000]	Speed: 45933.10 samples/sec
2018-01-22 01:04:55,513 Iter[2] Batch [1000] 	loss 6.6048638, ppl 738.6792317
2018-01-22 01:06:27,200 Iter[2] Batch [1200]	Speed: 44673.71 samples/sec
2018-01-22 01:06:27,201 Iter[2] Batch [1200] 	loss 6.5923242, ppl 729.4743591
2018-01-22 01:07:56,336 Iter[2] Batch [1400]	Speed: 45952.77 samples/sec
2018-01-22 01:07:56,336 Iter[2] Batch [1400] 	loss 6.5760327, ppl 717.6864072
2018-01-22 01:09:26,719 Iter[2] Batch [1600]	Speed: 45318.46 samples/sec
2018-01-22 01:09:26,719 Iter[2] Batch [1600] 	loss 6.5677529, ppl 711.7686506
2018-01-22 01:10:55,638 Iter[2] Batch [1800]	Speed: 46064.32 samples/sec
2018-01-22 01:10:55,639 Iter[2] Batch [1800] 	loss 6.5480693, ppl 697.8954706
2018-01-22 01:12:26,446 Iter[2] Batch [2000]	Speed: 45106.62 samples/sec
2018-01-22 01:12:26,446 Iter[2] Batch [2000] 	loss 6.5360054, ppl 689.5266661
2018-01-22 01:13:56,485 Iter[2] Batch [2200]	Speed: 45491.25 samples/sec
2018-01-22 01:13:56,486 Iter[2] Batch [2200] 	loss 6.5320791, ppl 686.8247064
2018-01-22 01:15:26,806 Iter[2] Batch [2400]	Speed: 45349.65 samples/sec
2018-01-22 01:15:26,807 Iter[2] Batch [2400] 	loss 6.5222773, ppl 680.1255026
2018-01-22 01:16:55,981 Iter[2] Batch [2600]	Speed: 45932.64 samples/sec
2018-01-22 01:16:55,981 Iter[2] Batch [2600] 	loss 6.5079688, ppl 670.4631552
2018-01-22 01:18:26,149 Iter[2] Batch [2800]	Speed: 45426.36 samples/sec
2018-01-22 01:18:26,150 Iter[2] Batch [2800] 	loss 6.4910918, ppl 659.2427296
2018-01-22 01:19:54,523 Iter[2] Batch [3000]	Speed: 46348.54 samples/sec
2018-01-22 01:19:54,524 Iter[2] Batch [3000] 	loss 6.4782656, ppl 650.8411642
2018-01-22 01:21:24,492 Iter[2] Batch [3200]	Speed: 45527.37 samples/sec
2018-01-22 01:21:24,492 Iter[2] Batch [3200] 	loss 6.4653389, ppl 642.4820426
2018-01-22 01:22:52,797 Iter[2] Batch [3400]	Speed: 46384.59 samples/sec
2018-01-22 01:22:52,798 Iter[2] Batch [3400] 	loss 6.4580688, ppl 637.8281232
2018-01-22 01:24:24,257 Saved checkpoint to "./checkpoint_1_test/-0000.params"
2018-01-22 01:25:15,327 Saved optimizer state to "./checkpoint_1_test/-0000.states"
2018-01-22 01:33:08,110 eval batch 199 : 5.6769878
2018-01-22 01:35:14,992 Iter[2]		 CE loss 5.6016586, ppl 270.8753037. Time cost = 598.21 seconds
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00008-of-00100
Finished processing!
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00004-of-00100
Finished processing!
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00002-of-00100
Finished processing!
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00009-of-00100
Finished processing!
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00003-of-00100
Finished processing!
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00005-of-00100
Finished processing!
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00006-of-00100
Finished processing!
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00001-of-00100
Finished processing!
[]
Processing file: /home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/news.en.heldout-00000-of-00050
Finished processing!
reset
reset
Processing file: /home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/news.en.heldout-00000-of-00050
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00004-of-00100
Finished processing!
Finished processing!
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00007-of-00100
Finished processing!
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00005-of-00100
Finished processing!
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00002-of-00100
Finished processing!
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00009-of-00100
Finished processing!
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00003-of-00100
Finished processing!
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00008-of-00100
Finished processing!
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00006-of-00100
Finished processing!
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00001-of-00100
Finished processing!
[]
Processing file: /home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/news.en.heldout-00000-of-00050
Finished processing!
reset
reset
Processing file: /home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/news.en.heldout-00000-of-00050
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00008-of-00100
Finished processing!
Finished processing!
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00004-of-00100
Finished processing!
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00003-of-00100
Finished processing!
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00006-of-00100
Finished processing!
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00001-of-00100
Finished processing!
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00007-of-00100
Finished processing!
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00002-of-00100
Finished processing!
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00005-of-00100
Finished processing!
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00009-of-00100
Finished processing!
[]
Processing file: /home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/news.en.heldout-00000-of-00050
Finished processing!
reset
reset
Processing file: 2018-01-22 01:36:47,483 Iter[3] Batch [200]	Speed: 45937.32 samples/sec
2018-01-22 01:36:47,484 Iter[3] Batch [200] 	loss 6.4607471, ppl 639.5386585
2018-01-22 01:38:18,969 Iter[3] Batch [400]	Speed: 44771.94 samples/sec
2018-01-22 01:38:18,970 Iter[3] Batch [400] 	loss 6.4113223, ppl 608.6980096
2018-01-22 01:39:47,276 Iter[3] Batch [600]	Speed: 46383.77 samples/sec
2018-01-22 01:39:47,277 Iter[3] Batch [600] 	loss 6.4108486, ppl 608.4097785
2018-01-22 01:41:18,390 Iter[3] Batch [800]	Speed: 44954.89 samples/sec
2018-01-22 01:41:18,391 Iter[3] Batch [800] 	loss 6.3978530, ppl 600.5542791
2018-01-22 01:42:48,087 Iter[3] Batch [1000]	Speed: 45665.16 samples/sec
2018-01-22 01:42:48,087 Iter[3] Batch [1000] 	loss 6.3800972, ppl 589.9850325
2018-01-22 01:44:19,437 Iter[3] Batch [1200]	Speed: 44838.80 samples/sec
2018-01-22 01:44:19,437 Iter[3] Batch [1200] 	loss 6.3690884, ppl 583.5256321
2018-01-22 01:45:48,948 Iter[3] Batch [1400]	Speed: 45760.01 samples/sec
2018-01-22 01:45:48,948 Iter[3] Batch [1400] 	loss 6.3663872, ppl 581.9515559
2018-01-22 01:47:19,334 Iter[3] Batch [1600]	Speed: 45317.02 samples/sec
2018-01-22 01:47:19,334 Iter[3] Batch [1600] 	loss 6.3614521, ppl 579.0866659
2018-01-22 01:48:48,279 Iter[3] Batch [1800]	Speed: 46050.74 samples/sec
2018-01-22 01:48:48,280 Iter[3] Batch [1800] 	loss 6.3559658, ppl 575.9183057
2018-01-22 01:50:19,110 Iter[3] Batch [2000]	Speed: 45094.85 samples/sec
2018-01-22 01:50:19,111 Iter[3] Batch [2000] 	loss 6.3458267, ppl 570.1084809
2018-01-22 01:51:48,128 Iter[3] Batch [2200]	Speed: 46013.35 samples/sec
2018-01-22 01:51:48,129 Iter[3] Batch [2200] 	loss 6.3288169, ppl 560.4930790
2018-01-22 01:53:18,542 Iter[3] Batch [2400]	Speed: 45303.07 samples/sec
2018-01-22 01:53:18,542 Iter[3] Batch [2400] 	loss 6.3225151, ppl 556.9720932
2018-01-22 01:54:48,252 Iter[3] Batch [2600]	Speed: 45658.26 samples/sec
2018-01-22 01:54:48,253 Iter[3] Batch [2600] 	loss 6.3175840, ppl 554.2323396
2018-01-22 01:56:19,743 Iter[3] Batch [2800]	Speed: 44769.66 samples/sec
2018-01-22 01:56:19,744 Iter[3] Batch [2800] 	loss 6.3098936, ppl 549.9864022
2018-01-22 01:57:48,777 Iter[3] Batch [3000]	Speed: 46005.16 samples/sec
2018-01-22 01:57:48,777 Iter[3] Batch [3000] 	loss 6.3010200, ppl 545.1276675
2018-01-22 01:59:19,842 Iter[3] Batch [3200]	Speed: 44979.28 samples/sec
2018-01-22 01:59:19,842 Iter[3] Batch [3200] 	loss 6.2891123, ppl 538.6749376
2018-01-22 02:00:49,266 Iter[3] Batch [3400]	Speed: 45804.46 samples/sec
2018-01-22 02:00:49,266 Iter[3] Batch [3400] 	loss 6.2754507, ppl 531.3658057
2018-01-22 02:02:15,105 Saved checkpoint to "./checkpoint_1_test/-0000.params"
2018-01-22 02:03:07,336 Saved optimizer state to "./checkpoint_1_test/-0000.states"
2018-01-22 02:11:34,477 eval batch 199 : 5.3429601
2018-01-22 02:13:44,595 Iter[3]		 CE loss 5.2736004, ppl 195.1172019. Time cost = 635.75 seconds
2018-01-22 02:15:17,959 Iter[4] Batch [200]	Speed: 45547.25 samples/sec
2018-01-22 02:15:17,959 Iter[4] Batch [200] 	loss 6.2943149, ppl 541.4847705
2018-01-22 02:16:48,840 Iter[4] Batch [400]	Speed: 45070.01 samples/sec
2018-01-22 02:16:48,841 Iter[4] Batch [400] 	loss 6.2512612, ppl 518.6665704
2018-01-22 02:18:18,514 Iter[4] Batch [600]	Speed: 45676.67 samples/sec
2018-01-22 02:18:18,515 Iter[4] Batch [600] 	loss 6.2365615, ppl 511.0980873
2018-01-22 02:19:50,359 Iter[4] Batch [800]	Speed: 44597.06 samples/sec
2018-01-22 02:19:50,360 Iter[4] Batch [800] 	loss 6.2285083, ppl 506.9986297
2018-01-22 02:21:19,530 Iter[4] Batch [1000]	Speed: 45934.79 samples/sec
2018-01-22 02:21:19,530 Iter[4] Batch [1000] 	loss 6.2119067, ppl 498.6511426
2018-01-22 02:22:51,357 Iter[4] Batch [1200]	Speed: 44605.46 samples/sec
2018-01-22 02:22:51,358 Iter[4] Batch [1200] 	loss 6.2124858, ppl 498.9399959
2018-01-22 02:24:21,091 Iter[4] Batch [1400]	Speed: 45646.25 samples/sec
2018-01-22 02:24:21,092 Iter[4] Batch [1400] 	loss 6.2158423, ppl 500.6174743
2018-01-22 02:25:52,919 Iter[4] Batch [1600]	Speed: 44605.28 samples/sec
2018-01-22 02:25:52,920 Iter[4] Batch [1600] 	loss 6.2094702, ppl 497.4376464
2018-01-22 02:27:22,885 Iter[4] Batch [1800]	Speed: 45528.81 samples/sec
2018-01-22 02:27:22,885 Iter[4] Batch [1800] 	loss 6.2035645, ppl 494.5085559
2018-01-22 02:28:53,996 Iter[4] Batch [2000]	Speed: 44956.44 samples/sec
2018-01-22 02:28:53,996 Iter[4] Batch [2000] 	loss 6.2024814, ppl 493.9732892
/home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00001-of-00100Processing file: /home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/news.en.heldout-00000-of-00050

Finished processing!
Finished processing!
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00008-of-00100
Finished processing!
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00009-of-00100
Finished processing!
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00006-of-00100
Finished processing!
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00004-of-00100
Finished processing!
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00003-of-00100
Finished processing!
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00007-of-00100
Finished processing!
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00002-of-00100
Finished processing!
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00005-of-00100
Finished processing!
[]
Processing file: /home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/news.en.heldout-00000-of-00050
Finished processing!
reset
reset
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00008-of-00100
Processing file: /home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/news.en.heldout-00000-of-00050
Finished processing!
Finished processing!
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00003-of-00100
Finished processing!
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00005-of-00100
Finished processing!
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00006-of-00100
Finished processing!
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00004-of-00100
Finished processing!
Processing file: /home/ubuntu/gbw-validation/training-monolingual.tokenized.shuffled/news.en-00009-of-00100
Finished processing!
Traceback (most recent call last):
  File "train.py", line 207, in <module>
    norm = module.clip_by_global_norm(max_norm=args.clip, param_names=lstm_args)
  File "/home/ubuntu/mxnet/python/mxnet/module/module.py", line 850, in clip_by_global_norm
    norm_val = self.global_grad_norm(grad_array)
  File "/home/ubuntu/mxnet/python/mxnet/module/module.py", line 917, in global_grad_norm
    norm_val += nd_global_norm(arr).asscalar()
  File "/home/ubuntu/mxnet/python/mxnet/ndarray/ndarray.py", line 1811, in asscalar
    return self.asnumpy()[0]
  File "/home/ubuntu/mxnet/python/mxnet/ndarray/ndarray.py", line 1793, in asnumpy
    ctypes.c_size_t(data.size)))
KeyboardInterrupt
