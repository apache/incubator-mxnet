PYTHONPATH=~/mxnet/python python train.py --nhid 256 --emsize 256 --batch_size=128 --k=8192 --num_proj=512 --dropout=0.01 --optimizer=adagrad --gpus=1 --checkpoint-dir=./checkpoint_1_test/ --data=/home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/*  --vocab=./data/1b_word_vocab.txt --lr=0.1 --log-interval=30 --nlayers=1 --clip=10 --init=uniform_unit  --checkpoint-interval=100 --epochs=40 &> 256-256-512-heldout

2018-01-08 23:45:17,487 Namespace(batch_size=128, bench=False, beta1=0.9, bptt=20, checkpoint_dir='./checkpoint_1_test/', checkpoint_interval=100, clip=10.0, clip_lstm=False, data='/home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/*', dense=False, dropout=0.01, emsize=256, epochs=40, gpus='1', init='uniform_unit', k=8192, kvstore='device', load_epoch=-1, log_interval=30, lr=0.1, minlr=1e-05, mom=0.0, nhid=256, nlayers=1, num_proj=512, optimizer='adagrad', profile=False, seed=1, tf_nce=False, vocab='./data/1b_word_vocab.txt', wd=0.0)
train.py:116: UserWarning: Optimizer created manually outside Module but rescale_grad is not normalized to 1.0/batch_size/num_workers (1.0 vs. 0.0078125). Is this intended?
  module.init_optimizer(optimizer=optimizer, kvstore=kvstore)
2018-01-08 23:45:28,918 Training started ... 
/home/ubuntu/mxnet/python/mxnet/ndarray/ndarray.py:1874: RuntimeWarning: You are attempting to copy an array to itself
  warnings.warn('You are attempting to copy an array to itself', RuntimeWarning)
2018-01-08 23:45:53,094 Iter[0] Batch [30]	Speed: 4847.01 samples/sec
2018-01-08 23:45:53,097 Iter[0] Batch [30] 	loss 90.4513003, ppl 1916463782946478791673909263305367617536.0000000
2018-01-08 23:46:06,073 Iter[0] Batch [60]	Speed: 5918.54 samples/sec
2018-01-08 23:46:06,073 Iter[0] Batch [60] 	loss 7.5229328, ppl 1849.9849516
2018-01-08 23:46:21,946 Iter[1] Batch [30]	Speed: 5799.09 samples/sec
2018-01-08 23:46:21,948 Iter[1] Batch [30] 	loss 7.0115295, ppl 1109.3499866
2018-01-08 23:46:35,266 Iter[1] Batch [60]	Speed: 5766.59 samples/sec
2018-01-08 23:46:35,266 Iter[1] Batch [60] 	loss 6.1714339, ppl 478.8722660
2018-01-08 23:46:51,158 Iter[2] Batch [30]	Speed: 5830.49 samples/sec
2018-01-08 23:46:51,158 Iter[2] Batch [30] 	loss 6.2464587, ppl 516.1816329
2018-01-08 23:47:04,252 Iter[2] Batch [60]	Speed: 5865.44 samples/sec
2018-01-08 23:47:04,253 Iter[2] Batch [60] 	loss 5.6334517, ppl 279.6256377
2018-01-08 23:47:17,639 Iter[3] Batch [30]	Speed: 7074.15 samples/sec
2018-01-08 23:47:17,640 Iter[3] Batch [30] 	loss 5.6885763, ppl 295.4726522
2018-01-08 23:47:27,980 Iter[3] Batch [60]	Speed: 7427.49 samples/sec
2018-01-08 23:47:27,981 Iter[3] Batch [60] 	loss 5.1556094, ppl 173.4014483
2018-01-08 23:47:41,715 Iter[4] Batch [30]	Speed: 6617.14 samples/sec
2018-01-08 23:47:41,716 Iter[4] Batch [30] 	loss 5.2288434, ppl 186.5768903
2018-01-08 23:47:53,137 Iter[4] Batch [60]	Speed: 6724.64 samples/sec
2018-01-08 23:47:53,137 Iter[4] Batch [60] 	loss 4.7851887, ppl 119.7239518
2018-01-08 23:48:07,070 Iter[5] Batch [30]	Speed: 6643.18 samples/sec
2018-01-08 23:48:07,074 Iter[5] Batch [30] 	loss 4.8145216, ppl 123.2878230
2018-01-08 23:48:18,508 Iter[5] Batch [60]	Speed: 6716.02 samples/sec
2018-01-08 23:48:18,509 Iter[5] Batch [60] 	loss 4.4056611, ppl 81.9132809
2018-01-08 23:48:31,041 Iter[6] Batch [30]	Speed: 7447.55 samples/sec
2018-01-08 23:48:31,042 Iter[6] Batch [30] 	loss 4.4348096, ppl 84.3360662
2018-01-08 23:48:41,903 Iter[6] Batch [60]	Speed: 7070.62 samples/sec
2018-01-08 23:48:41,904 Iter[6] Batch [60] 	loss 4.0435258, ppl 57.0270565
2018-01-08 23:48:54,928 Iter[7] Batch [30]	Speed: 7136.00 samples/sec
2018-01-08 23:48:54,929 Iter[7] Batch [30] 	loss 4.0652316, ppl 58.2784043
2018-01-08 23:49:08,368 Iter[7] Batch [60]	Speed: 5714.53 samples/sec
2018-01-08 23:49:08,373 Iter[7] Batch [60] 	loss 3.7030513, ppl 40.5709102
2018-01-08 23:49:24,623 Iter[8] Batch [30]	Speed: 5671.41 samples/sec
2018-01-08 23:49:24,626 Iter[8] Batch [30] 	loss 3.7348179, ppl 41.8803989
2018-01-08 23:49:38,600 Iter[8] Batch [60]	Speed: 5495.87 samples/sec
2018-01-08 23:49:38,600 Iter[8] Batch [60] 	loss 3.3815212, ppl 29.4154854
2018-01-08 23:49:55,242 Iter[9] Batch [30]	Speed: 5568.76 samples/sec
2018-01-08 23:49:55,242 Iter[9] Batch [30] 	loss 3.4225869, ppl 30.6485980
2018-01-08 23:50:09,210 Iter[9] Batch [60]	Speed: 5498.21 samples/sec
2018-01-08 23:50:09,212 Iter[9] Batch [60] 	loss 3.0935026, ppl 22.0541894
2018-01-08 23:50:25,604 Iter[10] Batch [30]	Speed: 5639.32 samples/sec
2018-01-08 23:50:25,605 Iter[10] Batch [30] 	loss 3.1373204, ppl 23.0420411
2018-01-08 23:50:39,565 Iter[10] Batch [60]	Speed: 5501.26 samples/sec
2018-01-08 23:50:39,566 Iter[10] Batch [60] 	loss 2.8385432, ppl 17.0908493
2018-01-08 23:50:55,824 Iter[11] Batch [30]	Speed: 5629.29 samples/sec
2018-01-08 23:50:55,826 Iter[11] Batch [30] 	loss 2.8883309, ppl 17.9633020
2018-01-08 23:51:09,545 Iter[11] Batch [60]	Speed: 5597.83 samples/sec
2018-01-08 23:51:09,546 Iter[11] Batch [60] 	loss 2.5922775, ppl 13.3601645
2018-01-08 23:51:26,037 Iter[12] Batch [30]	Speed: 5622.34 samples/sec
2018-01-08 23:51:26,037 Iter[12] Batch [30] 	loss 2.6725564, ppl 14.4769303
2018-01-08 23:51:39,666 Iter[12] Batch [60]	Speed: 5635.31 samples/sec
2018-01-08 23:51:39,666 Iter[12] Batch [60] 	loss 2.3764108, ppl 10.7661914
2018-01-08 23:51:56,162 Iter[13] Batch [30]	Speed: 5592.58 samples/sec
2018-01-08 23:51:56,165 Iter[13] Batch [30] 	loss 2.4676745, ppl 11.7949852
2018-01-08 23:52:09,744 Iter[13] Batch [60]	Speed: 5655.42 samples/sec
2018-01-08 23:52:09,745 Iter[13] Batch [60] 	loss 2.1821201, ppl 8.8650809
2018-01-08 23:52:26,172 Iter[14] Batch [30]	Speed: 5620.41 samples/sec
2018-01-08 23:52:26,173 Iter[14] Batch [30] 	loss 2.2596822, ppl 9.5800441
2018-01-08 23:52:39,613 Iter[14] Batch [60]	Speed: 5714.46 samples/sec
2018-01-08 23:52:39,613 Iter[14] Batch [60] 	loss 2.0019177, ppl 7.4032396
2018-01-08 23:52:55,937 Iter[15] Batch [30]	Speed: 5650.70 samples/sec
2018-01-08 23:52:55,937 Iter[15] Batch [30] 	loss 2.0801268, ppl 8.0054841
2018-01-08 23:53:09,693 Iter[15] Batch [60]	Speed: 5584.50 samples/sec
2018-01-08 23:53:09,695 Iter[15] Batch [60] 	loss 1.8392474, ppl 6.2918014
2018-01-08 23:53:25,857 Iter[16] Batch [30]	Speed: 5655.55 samples/sec
2018-01-08 23:53:25,857 Iter[16] Batch [30] 	loss 1.9113026, ppl 6.7618911
2018-01-08 23:53:39,488 Iter[16] Batch [60]	Speed: 5635.38 samples/sec
2018-01-08 23:53:39,488 Iter[16] Batch [60] 	loss 1.6871174, ppl 5.4038811
2018-01-08 23:53:56,191 Iter[17] Batch [30]	Speed: 5513.93 samples/sec
2018-01-08 23:53:56,193 Iter[17] Batch [30] 	loss 1.7519972, ppl 5.7661071
2018-01-08 23:54:10,177 Iter[17] Batch [60]	Speed: 5500.37 samples/sec
2018-01-08 23:54:10,181 Iter[17] Batch [60] 	loss 1.5450396, ppl 4.6881570
2018-01-08 23:54:26,752 Iter[18] Batch [30]	Speed: 5550.52 samples/sec
2018-01-08 23:54:26,753 Iter[18] Batch [30] 	loss 1.6059334, ppl 4.9825082
2018-01-08 23:54:40,416 Iter[18] Batch [60]	Speed: 5630.74 samples/sec
2018-01-08 23:54:40,419 Iter[18] Batch [60] 	loss 1.4142309, ppl 4.1133218
2018-01-08 23:54:56,534 Iter[19] Batch [30]	Speed: 5666.09 samples/sec
2018-01-08 23:54:56,535 Iter[19] Batch [30] 	loss 1.4696463, ppl 4.3476969
2018-01-08 23:55:10,406 Iter[19] Batch [60]	Speed: 5537.09 samples/sec
2018-01-08 23:55:10,410 Iter[19] Batch [60] 	loss 1.2933752, ppl 3.6450685
2018-01-08 23:55:26,915 Iter[20] Batch [30]	Speed: 5542.88 samples/sec
2018-01-08 23:55:26,916 Iter[20] Batch [30] 	loss 1.3490595, ppl 3.8537992
2018-01-08 23:55:41,036 Iter[20] Batch [60]	Speed: 5439.34 samples/sec
2018-01-08 23:55:41,038 Iter[20] Batch [60] 	loss 1.1836199, ppl 3.2661761
2018-01-08 23:55:57,887 Iter[21] Batch [30]	Speed: 5470.75 samples/sec
2018-01-08 23:55:57,887 Iter[21] Batch [30] 	loss 1.2340688, ppl 3.4351783
2018-01-08 23:56:11,697 Iter[21] Batch [60]	Speed: 5561.23 samples/sec
2018-01-08 23:56:11,697 Iter[21] Batch [60] 	loss 1.0860381, ppl 2.9625135
2018-01-08 23:56:28,517 Iter[22] Batch [30]	Speed: 5491.03 samples/sec
2018-01-08 23:56:28,517 Iter[22] Batch [30] 	loss 1.1248694, ppl 3.0798147
2018-01-08 23:56:39,156 Iter[22] Batch [60]	Speed: 7218.74 samples/sec
2018-01-08 23:56:39,157 Iter[22] Batch [60] 	loss 0.9919101, ppl 2.6963799
Processing file: /home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/news.en.heldout-00000-of-00050
Finished processing!
['lstm_l0_h2h_bias', 'lstm_l0_pj_bias', 'lstm_l0_i2h_weight', 'lstm_l0_i2h_bias', 'lstm_l0_pj_weight', 'lstm_l0_h2h_weight']
Processing file: /home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/news.en.heldout-00000-of-00050
Finished processing!
Processing file: /home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/news.en.heldout-00000-of-00050
Finished processing!
Processing file: /home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/news.en.heldout-00000-of-00050
Finished processing!
Processing file: /home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/news.en.heldout-00000-of-00050
Finished processing!
Processing file: /home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/news.en.heldout-00000-of-00050
Finished processing!
Processing file: /home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/news.en.heldout-00000-of-00050
Finished processing!
Processing file: /home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/news.en.heldout-00000-of-00050
Finished processing!
Processing file: /home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/news.en.heldout-00000-of-00050
Finished processing!
Processing file: /home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/news.en.heldout-00000-of-00050
Finished processing!
Processing file: /home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/news.en.heldout-00000-of-00050
Finished processing!
Processing file: /home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/news.en.heldout-00000-of-00050
Finished processing!
Processing file: /home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/news.en.heldout-00000-of-00050
Finished processing!
Processing file: /home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/news.en.heldout-00000-of-00050
Finished processing!
Processing file: /home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/news.en.heldout-00000-of-00050
Finished processing!
Processing file: /home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/news.en.heldout-00000-of-00050
Finished processing!
Processing file: /home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/news.en.heldout-00000-of-00050
Finished processing!
Processing file: /home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/news.en.heldout-00000-of-00050
Finished processing!
Processing file: /home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/news.en.heldout-00000-of-00050
Finished processing!
Processing file: /home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/news.en.heldout-00000-of-00050
Finished processing!
Processing file: /home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/news.en.heldout-00000-of-00050
Finished processing!
Processing file: /home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/news.en.heldout-00000-of-00050
Finished processing!
Processing file: /home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/news.en.heldout-00000-of-00050
Finished processing!
Processing file: /home/ubuntu/gbw-validation/heldout-monolingual.tokenized.shuffled/news.en.heldout-00000-of-00050
Finished processing!
Traceback (most recent call last):
  File "train.py", line 150, in <module>
    sample_ids, true_freq, sample_freq = sampler.sample(long(args.k), label.astype(np.int64).reshape((-1,)).asnumpy())
  File "/home/ubuntu/mxnet/python/mxnet/ndarray/ndarray.py", line 1793, in asnumpy
    ctypes.c_size_t(data.size)))
KeyboardInterrupt
