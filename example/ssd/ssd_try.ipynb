{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import os\n",
    "import zipfile\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## download pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_folder = os.path.join(os.getcwd(),'model','vgg16')\n",
    "os.mkdir(models_folder)\n",
    "zip_file = 'vgg16_reduced.zip'\n",
    "downloaded_zip_file = os.path.join(models_folder,zip_file)\n",
    "model_file =  os.path.join(models_folder,'vgg16_reduced-0001.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(model_file)==False:\n",
    "    wget.download('https://github.com/zhreshold/mxnet-ssd/releases/download/v0.2-beta/'+zip_file,models_folder)\n",
    "    with zipfile.ZipFile(\"file.zip\",\"r\") as zip_ref:\n",
    "        zip_ref.extractall(models_folder)\n",
    "    os.remove(downloaded_zip_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Voc data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pascal_folder = os.path.join(os.getcwd(),'data','VOCdevkit')\n",
    "request_url = 'http://host.robots.ox.ac.uk/pascal/VOC/'\n",
    "tar_files_list = ['VOCtrainval_11-May-2012.tar',]\n",
    "tar_file_folder_list = ['voc2012/','voc2012/','voc2007/']\n",
    "\n",
    "for tar_folder,tar_file in zip(tar_file_folder_list,tar_files_list):\n",
    "    download_url = tar_folder+tar_folder+tar_file\n",
    "    downloaded_tar = os.path(pascal_folder,tar_file)\n",
    "    #wget.download(download_url,pascal_folder)\n",
    "    tar = tarfile.open(osdownloaded_tar)\n",
    "    tar.extractall()\n",
    "    tar.close()\n",
    "    os.path.remove(downloaded_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_arguments()\n",
    "    default_args = pd.Series()\n",
    "    default_args['dataset'] = 'pascal'\n",
    "    'image_set' = 'trainval'\n",
    "    'year'=['2007','2012']\n",
    "    'val_image_set'='test'\n",
    "    'val_year'='2007'\n",
    "\n",
    "    parser.add_argument('--image-set', dest='image_set', help='train set, can be trainval or train',\n",
    "                        default='trainval', type=str)\n",
    "    parser.add_argument('--year', dest='year', help='can be 2007, 2012',\n",
    "                        default='2007,2012', type=str)\n",
    "    parser.add_argument('--val-image-set', dest='val_image_set', help='validation set, can be val or test',\n",
    "                        default='test', type=str)\n",
    "    parser.add_argument('--val-year', dest='val_year', help='can be 2007, 2010, 2012',\n",
    "                        default='2007', type=str)\n",
    "    parser.add_argument('--devkit-path', dest='devkit_path', help='VOCdevkit path',\n",
    "                        default=os.path.join(os.getcwd(), 'data', 'VOCdevkit'), type=str)\n",
    "    parser.add_argument('--network', dest='network', type=str, default='vgg16_reduced',\n",
    "                        choices=['vgg16_reduced'], help='which network to use')\n",
    "    parser.add_argument('--batch-size', dest='batch_size', type=int, default=32,\n",
    "                        help='training batch size')\n",
    "    parser.add_argument('--resume', dest='resume', type=int, default=-1,\n",
    "                        help='resume training from epoch n')\n",
    "    parser.add_argument('--finetune', dest='finetune', type=int, default=-1,\n",
    "                        help='finetune from epoch n, rename the model before doing this')\n",
    "    parser.add_argument('--pretrained', dest='pretrained', help='pretrained model prefix',\n",
    "                        default=os.path.join(os.getcwd(), 'model', 'vgg16_reduced'), type=str)\n",
    "    parser.add_argument('--epoch', dest='epoch', help='epoch of pretrained model',\n",
    "                        default=1, type=int)\n",
    "    parser.add_argument('--prefix', dest='prefix', help='new model prefix',\n",
    "                        default=os.path.join(os.getcwd(), 'model', 'ssd'), type=str)\n",
    "    parser.add_argument('--gpus', dest='gpus', help='GPU devices to train with',\n",
    "                        default='0', type=str)\n",
    "    parser.add_argument('--begin-epoch', dest='begin_epoch', help='begin epoch of training',\n",
    "                        default=0, type=int)\n",
    "    parser.add_argument('--end-epoch', dest='end_epoch', help='end epoch of training',\n",
    "                        default=100, type=int)\n",
    "    parser.add_argument('--frequent', dest='frequent', help='frequency of logging',\n",
    "                        default=20, type=int)\n",
    "    parser.add_argument('--data-shape', dest='data_shape', type=int, default=300,\n",
    "                        help='set image shape')\n",
    "    parser.add_argument('--lr', dest='learning_rate', type=float, default=0.001,\n",
    "                        help='learning rate')\n",
    "    parser.add_argument('--momentum', dest='momentum', type=float, default=0.9,\n",
    "                        help='momentum')\n",
    "    parser.add_argument('--wd', dest='weight_decay', type=float, default=0.0001,\n",
    "                        help='weight decay')\n",
    "    parser.add_argument('--mean-r', dest='mean_r', type=float, default=123,\n",
    "                        help='red mean value')\n",
    "    parser.add_argument('--mean-g', dest='mean_g', type=float, default=117,\n",
    "                        help='green mean value')\n",
    "    parser.add_argument('--mean-b', dest='mean_b', type=float, default=104,\n",
    "                        help='blue mean value')\n",
    "    parser.add_argument('--lr-epoch', dest='lr_refactor_epoch', type=int, default=50,\n",
    "                        help='refactor learning rate every N epoch')\n",
    "    parser.add_argument('--lr-ratio', dest='lr_refactor_ratio', type=float, default=0.9,\n",
    "                        help='ratio to refactor learning rate')\n",
    "    parser.add_argument('--log', dest='log_file', type=str, default=\"train.log\",\n",
    "                        help='save training log to file')\n",
    "    parser.add_argument('--monitor', dest='monitor', type=int, default=0,\n",
    "                        help='log network parameters every N iters if larger than 0')\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = parse_args()\n",
    "    ctx = [mx.gpu(int(i)) for i in args.gpus.split(',')]\n",
    "    ctx = mx.cpu() if not ctx else ctx\n",
    "    train_net(args.network, args.dataset, args.image_set, args.year,\n",
    "              args.devkit_path, args.batch_size,\n",
    "              args.data_shape, [args.mean_r, args.mean_g, args.mean_b],\n",
    "              args.resume, args.finetune, args.pretrained,\n",
    "              args.epoch, args.prefix, ctx, args.begin_epoch, args.end_epoch,\n",
    "              args.frequent, args.learning_rate, args.momentum, args.weight_decay,\n",
    "              args.val_image_set, args.val_year, args.lr_refactor_epoch,\n",
    "              args.lr_refactor_ratio, args.monitor, args.log_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
