{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import argparse\n",
    "import mxnet as mx\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(os.getcwd()))\n",
    "sys.path.append(os.path.join(os.getcwd(),'dataset'))\n",
    "sys.path.append(os.path.join(os.getcwd(),'train'))\n",
    "\n",
    "\n",
    "from train.train_net import train_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_parser():\n",
    "    parser = argparse.ArgumentParser(description='Train a Single-shot detection network')\n",
    "    parser.add_argument('--dataset', dest='dataset', help='which dataset to use',\n",
    "                        default='pascal', type=str)\n",
    "    parser.add_argument('--image-set', dest='image_set', help='train set, can be trainval or train',\n",
    "                        default='trainval', type=str)\n",
    "    parser.add_argument('--year', dest='year', help='can be 2007, 2012',\n",
    "                        default='2007,2012', type=str)\n",
    "    parser.add_argument('--val-image-set', dest='val_image_set', help='validation set, can be val or test',\n",
    "                        default='test', type=str)\n",
    "    parser.add_argument('--val-year', dest='val_year', help='can be 2007, 2010, 2012',\n",
    "                        default='2007', type=str)\n",
    "    parser.add_argument('--devkit-path', dest='devkit_path', help='VOCdevkit path',\n",
    "                        default=os.path.join(os.getcwd(), 'data', 'VOCdevkit'), type=str)\n",
    "    parser.add_argument('--network', dest='network', type=str, default='vgg16_reduced',\n",
    "                        choices=['vgg16_reduced'], help='which network to use')\n",
    "    parser.add_argument('--batch-size', dest='batch_size', type=int, default=32,\n",
    "                        help='training batch size')\n",
    "    parser.add_argument('--resume', dest='resume', type=int, default=-1,\n",
    "                        help='resume training from epoch n')\n",
    "    parser.add_argument('--finetune', dest='finetune', type=int, default=-1,\n",
    "                        help='finetune from epoch n, rename the model before doing this')\n",
    "    parser.add_argument('--pretrained', dest='pretrained', help='pretrained model prefix',\n",
    "                        default=os.path.join(os.getcwd(), 'model', 'vgg16_reduced'), type=str)\n",
    "    parser.add_argument('--epoch', dest='epoch', help='epoch of pretrained model',\n",
    "                        default=1, type=int)\n",
    "    parser.add_argument('--prefix', dest='prefix', help='new model prefix',\n",
    "                        default=os.path.join(os.getcwd(), 'model', 'ssd'), type=str)\n",
    "    parser.add_argument('--gpus', dest='gpus', help='GPU devices to train with',\n",
    "                        default='0', type=str)\n",
    "    parser.add_argument('--begin-epoch', dest='begin_epoch', help='begin epoch of training',\n",
    "                        default=0, type=int)\n",
    "    parser.add_argument('--end-epoch', dest='end_epoch', help='end epoch of training',\n",
    "                        default=100, type=int)\n",
    "    parser.add_argument('--frequent', dest='frequent', help='frequency of logging',\n",
    "                        default=20, type=int)\n",
    "    parser.add_argument('--data-shape', dest='data_shape', type=int, default=300,\n",
    "                        help='set image shape')\n",
    "    parser.add_argument('--lr', dest='learning_rate', type=float, default=0.001,\n",
    "                        help='learning rate')\n",
    "    parser.add_argument('--momentum', dest='momentum', type=float, default=0.9,\n",
    "                        help='momentum')\n",
    "    parser.add_argument('--wd', dest='weight_decay', type=float, default=0.0001,\n",
    "                        help='weight decay')\n",
    "    parser.add_argument('--mean-r', dest='mean_r', type=float, default=123,\n",
    "                        help='red mean value')\n",
    "    parser.add_argument('--mean-g', dest='mean_g', type=float, default=117,\n",
    "                        help='green mean value')\n",
    "    parser.add_argument('--mean-b', dest='mean_b', type=float, default=104,\n",
    "                        help='blue mean value')\n",
    "    parser.add_argument('--lr-epoch', dest='lr_refactor_epoch', type=int, default=50,\n",
    "                        help='refactor learning rate every N epoch')\n",
    "    parser.add_argument('--lr-ratio', dest='lr_refactor_ratio', type=float, default=0.9,\n",
    "                        help='ratio to refactor learning rate')\n",
    "    parser.add_argument('--log', dest='log_file', type=str, default=\"train.log\",\n",
    "                        help='save training log to file')\n",
    "    parser.add_argument('--monitor', dest='monitor', type=int, default=0,\n",
    "                        help='log network parameters every N iters if larger than 0')\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args =default_parser().parse_args(args='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Start training with (cpu(0)) from pretrained model /Users/imry/github_code/mxnet/example/ssd/model/vgg16_reduced\n",
      "INFO:root:Freezed parameters: [conv1_1_weight,conv1_1_bias,conv1_2_weight,conv1_2_bias,conv2_1_weight,conv2_1_bias,conv2_2_weight,conv2_2_bias]\n"
     ]
    }
   ],
   "source": [
    "ctx = [mx.gpu(int(i)) for i in args.gpus.split(',')]\n",
    "ctx = mx.cpu() if not ctx else ctx\n",
    "ctx = [mx.cpu()]\n",
    "train_net(args.network, args.dataset, args.image_set, args.year,\n",
    "          args.devkit_path, args.batch_size,\n",
    "          args.data_shape, [args.mean_r, args.mean_g, args.mean_b],\n",
    "          args.resume, args.finetune, args.pretrained,\n",
    "          args.epoch, args.prefix, ctx, args.begin_epoch, args.end_epoch,\n",
    "          args.frequent, args.learning_rate, args.momentum, args.weight_decay,\n",
    "          args.val_image_set, args.val_year, args.lr_refactor_epoch,\n",
    "          args.lr_refactor_ratio, args.monitor, args.log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook ssd_try.ipynb to python\r\n",
      "[NbConvertApp] Writing 5717 bytes to ssd_try.py\r\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to python ssd_try.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}