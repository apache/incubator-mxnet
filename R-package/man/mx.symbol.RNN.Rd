% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mxnet_generated.R
\name{mx.symbol.RNN}
\alias{mx.symbol.RNN}
\title{RNN:Apply a recurrent layer to input.}
\usage{
mx.symbol.RNN(...)
}
\arguments{
\item{data}{Symbol
Input data to RNN}

\item{parameters}{Symbol
Vector of all RNN trainable parameters concatenated}

\item{state}{Symbol
initial hidden state of the RNN}

\item{state.cell}{Symbol
initial cell state for LSTM networks (only for LSTM)}

\item{state.size}{int (non-negative), required
size of the state for each layer}

\item{num.layers}{int (non-negative), required
number of stacked layers}

\item{bidirectional}{boolean, optional, default=False
whether to use bidirectional recurrent layers}

\item{mode}{{'gru', 'lstm', 'rnn_relu', 'rnn_tanh'}, required
the type of RNN to compute}

\item{p}{float, optional, default=0
Dropout probability, fraction of the input that gets dropped out at training time}

\item{state.outputs}{boolean, optional, default=False
Whether to have the states as symbol outputs.}

\item{name}{string, optional
Name of the resulting symbol.}
}
\value{
out The result mx.symbol
}
\description{
RNN:Apply a recurrent layer to input.
}

