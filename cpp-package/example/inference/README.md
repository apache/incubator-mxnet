<!--- Licensed to the Apache Software Foundation (ASF) under one -->
<!--- or more contributor license agreements.  See the NOTICE file -->
<!--- distributed with this work for additional information -->
<!--- regarding copyright ownership.  The ASF licenses this file -->
<!--- to you under the Apache License, Version 2.0 (the -->
<!--- "License"); you may not use this file except in compliance -->
<!--- with the License.  You may obtain a copy of the License at -->

<!---   http://www.apache.org/licenses/LICENSE-2.0 -->

<!--- Unless required by applicable law or agreed to in writing, -->
<!--- software distributed under the License is distributed on an -->
<!--- "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY -->
<!--- KIND, either express or implied.  See the License for the -->
<!--- specific language governing permissions and limitations -->
<!--- under the License. -->

# MXNet C++ Package Inference Workflow Examples

## Building C++ Inference examples

The examples in this folder demonstrate the **inference** workflow. Please build the MXNet C++ Package as explained in the [README](<https://github.com/apache/incubator-mxnet/tree/master/cpp-package#building-c-package>) File before building these examples.
To build examples use following commands:

-  Release: **make all**
-  Debug: **make debug all**


## Examples demonstrating inference workflow

This directory contains following examples. In order to run the examples, ensure that the path to the MXNet shared library is added to the OS specific environment variable viz. **LD\_LIBRARY\_PATH** for Linux, Mac and Ubuntu OS and **PATH** for Windows OS.

## [imagenet_inference.cpp](<https://github.com/apache/incubator-mxnet/blob/master/cpp-package/example/inference/imagenet_inference.cpp>)

This example demonstrates image classification workflow with pre-trained models using MXNet C++ API. Now this script also supports inference with quantized CNN models generated by IntelÂ® MKL-DNN (see this [quantization flow](https://github.com/apache/incubator-mxnet/blob/master/example/quantization/README.md)). By using C++ API, the latency of most models can get **3%~10%** speedup compared with current Python implementation. The below tables show accuracy and latency of several CNN models.

The following models have been tested on Linux systems. And 50000 images are used to collect the following accuracy numbers.

| Model | Source | Dataset | FP32 Accuracy (top-1)| INT8 Accuracy (top-1)|
|:---|:---|---|:---:|:---:|
| [ResNet18-V1](#3)  | [Gluon-CV](https://gluon-cv.mxnet.io/model_zoo/classification.html)  | [Validation Dataset](http://data.mxnet.io/data/val_256_q90.rec)  |70.15%|69.92%|
| [ResNet50-V1](#3)  | [Gluon-CV](https://gluon-cv.mxnet.io/model_zoo/classification.html)  | [Validation Dataset](http://data.mxnet.io/data/val_256_q90.rec)  |76.34%|  75.91% |
| [ResNet101-V1](#3)  | [Gluon-CV](https://gluon-cv.mxnet.io/model_zoo/classification.html)  | [Validation Dataset](http://data.mxnet.io/data/val_256_q90.rec)  | 77.33%  | 77.05% |
|[Squeezenet 1.0](#4)|[Gluon-CV](https://gluon-cv.mxnet.io/model_zoo/classification.html)|[Validation Dataset](http://data.mxnet.io/data/val_256_q90.rec)| 56.98%| 52.98%|
|[MobileNet 1.0](#5)|[Gluon-CV](https://gluon-cv.mxnet.io/model_zoo/classification.html)|[Validation Dataset](http://data.mxnet.io/data/val_256_q90.rec)|72.23%|72.03%|
|[MobileNetV2 1.0](#6)|[Gluon-CV](https://gluon-cv.mxnet.io/model_zoo/classification.html)|[Validation Dataset](http://data.mxnet.io/data/val_256_q90.rec)|70.27%|69.70%|
|[Inception V3](#7)|[Gluon-CV](https://gluon-cv.mxnet.io/model_zoo/classification.html)|[Validation Dataset](http://data.mxnet.io/data/val_256_q90.rec)|77.76% |77.87% |
|[ResNet152-V2](#8)|[MXNet ModelZoo](http://data.mxnet.io/models/imagenet/resnet/152-layers/)|[Validation Dataset](http://data.mxnet.io/data/val_256_q90.rec)|76.65%|76.36%|
|[Inception-BN](#9)|[MXNet ModelZoo](http://data.mxnet.io/models/imagenet/inception-bn/)|[Validation Dataset](http://data.mxnet.io/data/val_256_q90.rec)|72.28%|72.20%|

The following performance numbers are collected by using Skylake 6148 with 20 physical cores.

| Model | Dataset |C++ latency (imgs/sec) |Python latency (imgs/sec) |
|:---|:---|:---:|:---:|
| |  |FP32 / INT8 | FP32 / INT8 |
| [ResNet18-V1](#3)  | [Validation Dataset](http://data.mxnet.io/data/val_256_q90.rec)  |214.43 / 316.75|204.34 / 292.26|
| [ResNet50-V1](#3)  | [Validation Dataset](http://data.mxnet.io/data/val_256_q90.rec)  |95.72 / 152.25|92.37 / 145.21 |
| [ResNet101-V1](#3) | [Validation Dataset](http://data.mxnet.io/data/val_256_q90.rec)  | 53.27 / 81.35| 51.74 / 78.41|
|[Squeezenet 1.0](#4)|[Validation Dataset](http://data.mxnet.io/data/val_256_q90.rec)| 193.81 /  377.94| 177.68 / 346.64|
|[MobileNet 1.0](#5)|[Validation Dataset](http://data.mxnet.io/data/val_256_q90.rec)|312.71 /  338.19|288.10 / 311.12|
|[MobileNetV2 1.0](#6)|[Validation Dataset](http://data.mxnet.io/data/val_256_q90.rec)|196.09 / 354.28|177.05 / 321.48|
|[Inception V3](#7)|[Validation Dataset](http://data.mxnet.io/data/val_256_q90.rec)|62.03 /  93.45 | 59.78 / 89.77 |
|[ResNet152-V2](#8)|[Validation Dataset](http://data.mxnet.io/data/val_256_q90.rec)|31.37 / 37.59|30.53 / 36.12 |
|[Inception-BN](#9)|[Validation Dataset](http://data.mxnet.io/data/val_256_q90.rec)| 120.95 / 159.67| 116.23 / 150.30|

The command line to launch inference by this script can accept are as shown below:
```
./imagenet_inference --help
Usage:
imagenet_inference  --symbol_file <model symbol file in json format>
                    --params_file <model params file>
		    --dataset <dataset used to benchmark>
		    --data_nthreads <number of threads for data decoding, default: 60>
		    --input_shape <shape of input image e.g "3 224 224">]
		    --rgb_mean <mean value to be subtracted on R/G/B channel e.g "0 0 0">
		    --rgb_std <standard deviation on R/G/B channel. e.g "1 1 1">
		    --batch_size <number of images per batch>
		    --num_skipped_batches <skip the number of batches for inference>
		    --num_inference_batches <number of batches used for inference>
		    --data_layer_type <default: "float32", choices: ["float32", "int8", "uint8"]>
		    --gpu <whether to run inference on GPU, default: false>
		    --benchmark <whether to use dummy data to run inference, default: false>
```

Follow the below steps to do inference with more models.

- Download the pre-trained FP32 models into ```./model``` directory.
- Refer this [README](https://github.com/apache/incubator-mxnet/blob/master/example/quantization/README.md) to generate the corresponding quantized models and also put them into ```./model``` directory.
- Prepare [validation dataset](http://data.mxnet.io/data/val_256_q90.rec) and put it into ```./data``` directory.

The below command lines show how to run inference with FP32/INT8 resnet50_v1 model. Because the C++ inference script provides the almost same command line as this [Python script](https://github.com/apache/incubator-mxnet/blob/master/example/quantization/imagenet_inference.py) and then users can easily go from Python to C++.
```
# set MKLDNN as subgraph backend
export MXNET_SUBGRAPH_BACKEND=MKLDNN

# FP32 inference
./imagenet_inference --symbol_file "./model/resnet50_v1-symbol.json" --params_file "./model/resnet50_v1-0000.params" --dataset "./data/val_256_q90.rec" --rgb_mean "123.68 116.779 103.939" --rgb_std "58.393 57.12 57.375" --batch_size 64 --num_skipped_batches 50 --num_inference_batches 500

# INT8 inference
./imagenet_inference --symbol_file "./model/resnet50_v1-quantized-5batches-naive-symbol.json" --params_file "./model/resnet50_v1-quantized-0000.params" --dataset "./data/val_256_q90.rec" --rgb_mean "123.68 116.779 103.939" --rgb_std "58.393 57.12 57.375" --batch_size 64 --num_skipped_batches 50 --num_inference_batches 500

# FP32 dummy data
./imagenet_inference --symbol_file "./model/resnet50_v1-symbol.json" --batch_size 64 --num_inference_batches 500 --benchmark

# INT8 dummy data
./imagenet_inference --symbol_file "./model/resnet50_v1-quantized-5batches-naive-symbol.json" --batch_size 64 --num_inference_batches 500 --benchmark

```
For a quickly inference test, users can directly run [unit_test_imagenet_inference.sh](<https://github.com/apache/incubator-mxnet/blob/master/cpp-package/example/inference/unit_test_imagenet_inference.sh>) by using the below command. This script will automatically download the pre-trained **Inception-Bn** and **resnet50_v1_int8** model and **validation dataset** which are required for inference.

```
./unit_test_imagenet_inference.sh
```
And you may get the similiar outputs like below:
```
>>> INFO: FP32 real data
imagenet_inference.cpp:253: Loading the model from ./model/Inception-BN-symbol.json
imagenet_inference.cpp:266: Loading the model parameters from ./model/Inception-BN-0126.params
INFO:Dataset for inference: ./data/val_256_q90.rec
INFO:label_name = softmax_label
INFO:rgb_mean: (123.68, 116.779, 103.939)
INFO:rgb_std: (1, 1, 1)
INFO:Image shape: (3, 224, 224)
INFO:Finished inference with: 500 images
INFO:Batch size = 1 for inference
INFO:Accuracy: 0.744
INFO:Throughput: xxxx images per second

>>> INFO: FP32 dummy data
imagenet_inference.cpp:253: Loading the model from ./model/Inception-BN-symbol.json
imagenet_inference.cpp:354: benchmark completed!
imagenet_inference.cpp:355: batch size: 1 num batch: 500 throughput: xxxx imgs/s latency: xxxx ms

>>> INFO: INT8 dummy data
imagenet_inference.cpp:253: Loading the model from ./model/resnet50_v1_int8-symbol.json
imagenet_inference.cpp:354: benchmark completed!
imagenet_inference.cpp:355: batch size: 1 num batch: 500 throughput: xxxx imgs/s latency: xxxx ms
```

## [sentiment_analysis_rnn.cpp](<https://github.com/apache/incubator-mxnet/blob/master/cpp-package/example/inference/sentiment_analysis_rnn.cpp>)
This example demonstrates how you can load a pre-trained RNN model and use it to predict the sentiment expressed in the given movie review with the MXNet C++ API. The example is capable of processing variable legnth inputs. It performs the following tasks
- Loads the pre-trained RNN model.
- Loads the dictionary file containing the word to index mapping.
- Splits the review in multiple lines separated by "."
- The example predicts the sentiment score for individual lines and outputs the average score.

The example is capable of processing variable length input by implementing following technique:
- The example creates executors for pre-determined input lenghts such as 5, 10, 15, 20, 25, etc called **buckets**.
- Each bucket is identified by **bucket-key** representing the length on input required by corresponding executor.
- For each line in the review, the example finds the number of words in the line and tries to find a closest bucket or executor.
- If the bucket key does not match the number of words in the line, the example pads or trims the input line to match the required length.

The example uses a pre-trained RNN model trained with a IMDB dataset. The RNN model was built by exercising the [GluonNLP Sentiment Analysis Tutorial](<http://gluon-nlp.mxnet.io/examples/sentiment_analysis/sentiment_analysis.html#>). The tutorial uses 'standard_lstm_lm_200' available in Gluon Model Zoo and fine tunes it for the IMDB dataset
The model consists of :
- Embedding Layer
- 2 LSTM Layers with hidden dimension size of 200
- Average pooling layer
- Sigmoid output layer
The model was trained for 10 epochs to achieve 85% test accuracy.
The visual representation of the model is [here](<http://gluon-nlp.mxnet.io/examples/sentiment_analysis/sentiment_analysis.html#Sentiment-analysis-model-with-pre-trained-language-model-encoder>).

The model files can be found here.
- [sentiment_analysis-symbol.json](< https://s3.amazonaws.com/mxnet-cpp/RNN_model/sentiment_analysis-symbol.json>)
- [sentiment_analysis-0010.params](< https://s3.amazonaws.com/mxnet-cpp/RNN_model/sentiment_analysis-0010.params>)
- [sentiment_token_to_idx.txt](<https://s3.amazonaws.com/mxnet-cpp/RNN_model/sentiment_token_to_idx.txt>) Each line of the dictionary file contains a word and a unique index for that word, separated by a space, with a total of 32787 words generated from the training dataset.
The example downloads the above files while running.

The example's command line parameters are as shown below:

```
./sentiment_analysis_rnn --help
Usage:
sentiment_analysis_rnn
--input Input movie review. The review can be single line or multiline.e.g. "This movie is the best." OR  "This movie is the best. The direction is awesome."
[--gpu]  Specify this option if workflow needs to be run in gpu context
If the review is multiline, the example predicts sentiment score for each line and the final score is the average of scores obtained for each line.

```

The following command line shows running the example with the movie review containing only one line.

```
./sentiment_analysis_rnn --input "This movie has the great story"
```

The above command will output the sentiment score as follows:
```
sentiment_analysis_rnn.cpp:346: Input Line : [This movie has the great story] Score : 0.999898
sentiment_analysis_rnn.cpp:449: The sentiment score between 0 and 1, (1 being positive)=0.999898
```

The following command line shows invoking the example with the multi-line review.

```
./sentiment_analysis_rnn --input "This movie is the best. The direction is awesome."
```
The above command will output the sentiment score for each line in the review and average score as follows:
```
Input Line : [This movie is the best] Score : 0.964498
Input Line : [ The direction is awesome] Score : 0.968855
The sentiment score between 0 and 1, (1 being positive)=0.966677
```

Alternatively, you can run the [unit_test_sentiment_analysis_rnn.sh](<https://github.com/apache/incubator-mxnet/blob/master/cpp-package/example/inference/unit_test_sentiment_analysis_rnn.sh>) script.
